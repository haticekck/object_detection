{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/content/data/data'\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    images_dir = os.path.join(root_dir, 'images', split)\n",
    "    labels_dir = os.path.join(root_dir, 'rcnn_labels', split)  # Dönüştürülmüş label için\n",
    "    orig_labels_dir = os.path.join(root_dir, 'labels', split)  # Orijinal YOLO label için\n",
    "\n",
    "    images_count = len([f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    labels_count = len([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "    orig_labels_count = len([f for f in os.listdir(orig_labels_dir) if f.endswith('.txt')])\n",
    "\n",
    "    print(f\"\\n{split.upper()} klasörü:\")\n",
    "    print(f\"Images: {images_count}\")\n",
    "    print(f\"RCNN labels: {labels_count}\")\n",
    "    print(f\"YOLO labels: {orig_labels_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42eea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/content/data/data'\n",
    "splits = ['train', 'val']\n",
    "\n",
    "for split in splits:\n",
    "    yolo_labels_dir = os.path.join(root_dir, 'labels', split)\n",
    "    yolo_images_dir = os.path.join(root_dir, 'images', split)\n",
    "    rcnn_labels_dir = os.path.join(root_dir, 'rcnn_labels', split)\n",
    "\n",
    "    os.makedirs(rcnn_labels_dir, exist_ok=True)\n",
    "\n",
    "    for label_file in os.listdir(yolo_labels_dir):\n",
    "        yolo_label_path = os.path.join(yolo_labels_dir, label_file)\n",
    "        image_name = label_file.replace('.txt', '.jpg')\n",
    "        image_path = os.path.join(yolo_images_dir, image_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        W, H = img.size\n",
    "\n",
    "        with open(yolo_label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            cls = int(parts[0])\n",
    "            x_c, y_c, w, h = map(float, parts[1:])\n",
    "\n",
    "            xmin = int((x_c - w/2) * W)\n",
    "            ymin = int((y_c - h/2) * H)\n",
    "            xmax = int((x_c + w/2) * W)\n",
    "            ymax = int((y_c + h/2) * H)\n",
    "\n",
    "            # Faster R-CNN format: xmin ymin xmax ymax class\n",
    "            new_line = f\"{xmin} {ymin} {xmax} {ymax} {cls}\\n\"\n",
    "            new_lines.append(new_line)\n",
    "\n",
    "        out_path = os.path.join(rcnn_labels_dir, label_file)\n",
    "        with open(out_path, 'w') as out_f:\n",
    "            out_f.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train directory\n",
    "images_dir = '/content/data/data/images/train'\n",
    "labels_dir = '/content/data/data/rcnn_labels/train'  \n",
    "\n",
    "image_files = set([os.path.splitext(f)[0] for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "label_files = set([os.path.splitext(f)[0] for f in os.listdir(labels_dir)])\n",
    "\n",
    "images_without_labels = image_files - label_files\n",
    "print(\"Label'ı olmayan image dosyaları:\", images_without_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_base in images_without_labels:\n",
    "    for ext in ['.jpg', '.png']:\n",
    "        img_path = os.path.join(images_dir, img_base + ext)\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"Silindi: {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For val directory\n",
    "images_dir = '/content/data/data/images/val'\n",
    "labelsrcnn_dir = '/content/data/data/rcnn_labels/val'\n",
    "\n",
    "image_basenames = set(os.path.splitext(f)[0] for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png'))\n",
    "label_basenames = set(os.path.splitext(f)[0] for f in os.listdir(labelsrcnn_dir) if f.endswith('.txt'))\n",
    "\n",
    "images_without_labels = image_basenames - label_basenames\n",
    "\n",
    "print(\"Label'ı olmayan image dosyaları:\")\n",
    "for img_base in images_without_labels:\n",
    "    print(img_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_base in images_without_labels:\n",
    "    for ext in ['.jpg', '.png']:\n",
    "        img_path = os.path.join(images_dir, img_base + ext)\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"Silindi: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, transforms=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(self.images_dir)))\n",
    "        self.boxes = list(sorted(os.listdir(self.labels_dir)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        box_path = os.path.join(self.labels_dir, self.boxes[idx])\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(box_path) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                xmin, ymin, xmax, ymax, label = map(float, parts)\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(int(label))\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        else:\n",
    "            img = F.to_tensor(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir = '/content/data/data/images/train'\n",
    "train_labels_dir = '/content/data/data/rcnn_labels/train'\n",
    "val_images_dir = '/content/data/data/images/val'\n",
    "val_labels_dir = '/content/data/data/rcnn_labels/val'\n",
    "\n",
    "train_dataset = CustomDataset(train_images_dir, train_labels_dir)\n",
    "val_dataset = CustomDataset(val_images_dir, val_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45148b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "# Pretrained model\n",
    "model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "n_samples = 250\n",
    "\n",
    "# Lists to save losses\n",
    "train_epoch_losses = []\n",
    "val_epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Random subset for each epoch\n",
    "    indices = np.random.choice(len(train_dataset), n_samples, replace=False)\n",
    "    subset_train_dataset = Subset(train_dataset, indices)\n",
    "    train_loader = DataLoader(\n",
    "        subset_train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Train\n",
    "    for images, targets in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_epoch_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation (Val)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(val_loader, desc=f\"Val Epoch {epoch+1}\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Çoğu PyTorch sürümünde: model(images, targets) -> dict (losslar)\n",
    "            out = model(images, targets)\n",
    "            if isinstance(out, dict):\n",
    "                losses = sum(loss for loss in out.values())\n",
    "                val_loss += losses.item()\n",
    "                val_batches += 1\n",
    "            else:\n",
    "                # Sadece prediction dönüyorsa validation loss kaydedilmez\n",
    "                print(\"Uyarı: Eval modda loss alınamıyor, sadece prediction döndü.\")\n",
    "                break\n",
    "    avg_val_loss = val_loss / val_batches if val_batches > 0 else None\n",
    "    val_epoch_losses.append(avg_val_loss)\n",
    "\n",
    "    # (Optional) Learning rate scheduler\n",
    "    if 'lr_scheduler' in locals():\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Avg Loss: {avg_train_loss:.4f}, Val Avg Loss: {avg_val_loss}\")\n",
    "\n",
    "    # To save the model at the end of each epoch\n",
    "    # torch.save(model.state_dict(), f'/content/data/data/rcnn_labels/fasterrcnn_epoch{epoch+1}.pth')\n",
    "\n",
    "# Save last model weights\n",
    "torch.save(model.state_dict(), '/content/data/data/fasterrcnn_final.pth')\n",
    "print(\"Model is saved: /content/data/data/fasterrcnn_final.pth\")\n",
    "\n",
    "# Save Train and Val Losses\n",
    "loss_df = pd.DataFrame({\n",
    "    'epoch': list(range(1, num_epochs+1)),\n",
    "    'train_loss': train_epoch_losses,\n",
    "    'val_loss': val_epoch_losses\n",
    "})\n",
    "loss_df.to_csv('/content/data/data/training_log.csv', index=False)\n",
    "print(\"Losses are saved: /content/data/data/training_log.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
