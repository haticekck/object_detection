{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0057bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Patch numpy float for ByteTrack compatibility\n",
    "np.float = float\n",
    "\n",
    "# Add ByteTrack repo to sys.path\n",
    "sys.path.append('./ByteTrack')\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9035908",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ifzhang/ByteTrack.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ByteTrack\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import sys\n",
    "sys.path.append('/content/ByteTrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.float = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model (update path as needed)\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Set ByteTrack tracker parameters\n",
    "class Args:\n",
    "    track_thresh = 0.5\n",
    "    track_buffer = 30\n",
    "    match_thresh = 0.8\n",
    "    min_box_area = 10\n",
    "    mot20 = False\n",
    "\n",
    "tracker = BYTETracker(Args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2196518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input video path\n",
    "video_path = 'traffic.mp4'\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_tracked.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Get class name mapping from YOLO model\n",
    "class_names = model.names if isinstance(model.names, dict) else dict(enumerate(model.names))\n",
    "\n",
    "# Prepare results file\n",
    "result_file = open('results.txt', 'w')\n",
    "\n",
    "# IDs of classes to track, according to your data.yaml ['others', 'car', 'van', 'bus']\n",
    "follow_classes = [0, 1, 2, 3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4996ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 0\n",
    "id_offset = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_id += 1\n",
    "\n",
    "    # Run YOLO detection on the frame\n",
    "    results = model.predict(source=frame, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    # Filter only selected vehicle classes\n",
    "    vehicle_indices = np.where(np.isin(classes, follow_classes))[0]\n",
    "    dets = []\n",
    "    det_classes = []\n",
    "    for idx in vehicle_indices:\n",
    "        x1, y1, x2, y2 = boxes[idx]\n",
    "        score = scores[idx]\n",
    "        dets.append([x1, y1, x2, y2, score])\n",
    "        det_classes.append(int(classes[idx]))\n",
    "    dets = np.array(dets)\n",
    "    if len(dets) == 0:\n",
    "        dets = np.empty((0, 5))\n",
    "\n",
    "    img_info = [frame.shape[0], frame.shape[1]]\n",
    "    img_size = (frame.shape[0], frame.shape[1])\n",
    "\n",
    "    # Track objects using ByteTrack\n",
    "    online_targets = tracker.update(dets, img_info, img_size)\n",
    "\n",
    "    # Set ID offset for shifting IDs to start from 1\n",
    "    if id_offset is None:\n",
    "        if len(online_targets) > 0:\n",
    "            id_offset = min([t.track_id for t in online_targets])\n",
    "        else:\n",
    "            id_offset = 0\n",
    "\n",
    "    active_ids = []\n",
    "    # Draw boxes, labels, and save to txt\n",
    "    for t in online_targets:\n",
    "        tlwh = t.tlwh\n",
    "        track_id = t.track_id\n",
    "        shifted_id = track_id - id_offset + 1  # Shift IDs to start from 1\n",
    "        active_ids.append(shifted_id)\n",
    "\n",
    "        # Find class name by matching detection to track with IoU\n",
    "        t_box = np.array([tlwh[0], tlwh[1], tlwh[0]+tlwh[2], tlwh[1]+tlwh[3]])\n",
    "        best_iou = 0\n",
    "        best_cls = -1\n",
    "        for det_box, cls in zip(dets, det_classes):\n",
    "            xx1 = max(t_box[0], det_box[0])\n",
    "            yy1 = max(t_box[1], det_box[1])\n",
    "            xx2 = min(t_box[2], det_box[2])\n",
    "            yy2 = min(t_box[3], det_box[3])\n",
    "            w = max(0., xx2-xx1)\n",
    "            h = max(0., yy2-yy1)\n",
    "            intersection = w * h\n",
    "            area1 = (t_box[2]-t_box[0]) * (t_box[3]-t_box[1])\n",
    "            area2 = (det_box[2]-det_box[0]) * (det_box[3]-det_box[1])\n",
    "            union = area1 + area2 - intersection\n",
    "            iou = intersection / union if union > 0 else 0\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_cls = cls\n",
    "\n",
    "        class_name = class_names.get(best_cls, \"unknown\")\n",
    "        x1, y1, w, h = [int(i) for i in tlwh]\n",
    "        # Draw bounding box and label on the frame\n",
    "        cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0,255,0), 2)\n",
    "        label = f\"{shifted_id}: {class_name}\"\n",
    "        cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "        # Write results to text file (frame_id, class_name, x1, y1, w, h)\n",
    "        result_file.write(f\"{frame_id},{class_name},{x1},{y1},{w},{h}\\n\")\n",
    "\n",
    "    # Calculate traffic density level based on active vehicle count\n",
    "    active_vehicle_count = len(active_ids)\n",
    "    if active_vehicle_count <= 5:\n",
    "        density_level = \"Low\"\n",
    "    elif active_vehicle_count <= 10:\n",
    "        density_level = \"Medium\"\n",
    "    else:\n",
    "        density_level = \"High\"\n",
    "\n",
    "    # Write traffic density text at the bottom of the frame\n",
    "    cv2.putText(frame, f\"Traffic: {density_level}\", (50, height - 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 6)\n",
    "\n",
    "    # Write the processed frame to output video\n",
    "    out.write(frame)\n",
    "    print(f\"Frame {frame_id} processed, {len(online_targets)} vehicles tracked.\")\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "result_file.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
